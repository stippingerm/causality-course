{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14bef34d",
   "metadata": {},
   "source": [
    "# Inference of causal graphs from data\n",
    "\n",
    "Author: Marcell Stippinger\n",
    "\n",
    "Date: 2025-10-10\n",
    "\n",
    "## Contents\n",
    "\n",
    "* Generate and fit VAR and VMA models\n",
    "* Analyze Granger causality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf234c26",
   "metadata": {},
   "source": [
    "## Imports and plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be97520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.utils import check_random_state\n",
    "from typing import NamedTuple, Optional, Tuple, Any\n",
    "#stationarity testing\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "#autocorrelation and partial autocorrelation\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "#VAR and VMA models\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "from statsmodels.tsa.api import VARMAX\n",
    "# Granger causality test\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7853c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ts(X, E=None):\n",
    "    \"\"\"Plot time series data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Time series data to plot.\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    fig, axes = plt.subplots(n_features, 1, figsize=(6, 4), sharex=True)\n",
    "    if n_features == 1:\n",
    "        axes = [axes]\n",
    "    for i in range(n_features):\n",
    "        axes[i].axhline(0, color='gray', linestyle='--', linewidth=0.5)\n",
    "        axes[i].plot(X[:, i])\n",
    "        if E is not None:\n",
    "            axes[i].plot(E[:, i], linestyle='None', marker='o', markersize=3, alpha=0.7, label='Noise')\n",
    "        axes[i].set_title(f'Time Series {i+1}')\n",
    "        axes[i].set_ylabel('Value')\n",
    "    axes[-1].set_xlabel('Time')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddd2a33",
   "metadata": {},
   "source": [
    "## VAR(p) models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08290cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_var_by_hand(k: int, p: int, n: int, seed: int = None,\n",
    "                    coeff_max: float = 0.5, coupling_mask: np.array = 1,\n",
    "                    return_noise: bool = False):\n",
    "    \"\"\"\n",
    "    Generate a VAR(p) process by hand.\n",
    "    \n",
    "    Parameters:\n",
    "    k (int): Number of variables.\n",
    "    p (int): Order of the VAR process.\n",
    "    n (int): Length of the time series to generate.\n",
    "    seed (int, optional): Random seed for reproducibility. Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: Generated VAR(p) time series of shape (n, k).\n",
    "    \"\"\"\n",
    "    rng = check_random_state(seed)\n",
    "    burn_in = 100\n",
    "    \n",
    "    # Generate random coefficients for the VAR(p) model\n",
    "    A = [coupling_mask * rng.uniform(-coeff_max, coeff_max, size=(k, k)) for _ in range(p)]\n",
    "    \n",
    "    # Initialize the time series with zeros\n",
    "    Y = np.zeros((n + burn_in, k))  # Extra 100 for burn-in\n",
    "    \n",
    "    # Generate white noise\n",
    "    E = rng.normal(size=(n + burn_in, k))\n",
    "    \n",
    "    # Generate the VAR(p) process\n",
    "    for t in range(p, n + burn_in):\n",
    "        Y[t] = sum(A[i] @ Y[t - i - 1] for i in range(p)) + E[t]\n",
    "    \n",
    "    if return_noise:\n",
    "        return A, Y[burn_in:], E[burn_in:]  # Discard the burn-in period\n",
    "    return A, Y[burn_in:]  # Discard the burn-in period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0985eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_var_coeff, ts_var, ts_var_drive = gen_var_by_hand(2, 3, 200, coeff_max=0.5, seed=20251010, return_noise=True)\n",
    "plot_ts(ts_var, ts_var_drive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a6ab89",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- use a single time series\n",
    "- explore the effect of model order $p$\n",
    "- explore the effect of coeff_max on stationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b597f1e",
   "metadata": {},
   "source": [
    "## VMA(q) models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ba31b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_vma_by_hand(k: int, q: int, n: int, seed=20251010,\n",
    "                    coeff_min: float = -0.5, coeff_max: float = 0.5, coupling_mask: np.array = 1,\n",
    "                    return_noise: bool = False):\n",
    "    \"\"\"\n",
    "    Generate a VMA(q) process by hand.\n",
    "    \n",
    "    Parameters:\n",
    "    k (int): Number of variables.\n",
    "    q (int): Order of the VMA process.\n",
    "    n (int): Length of the time series to generate.\n",
    "    seed (int, optional): Random seed for reproducibility. Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: Generated VMA(q) time series of shape (n, k).\n",
    "    \"\"\"\n",
    "    rng = check_random_state(seed)\n",
    "    burn_in = 100\n",
    "    \n",
    "    # Generate random coefficients for the VMA(q) model\n",
    "    B = [coupling_mask * rng.uniform(coeff_min, coeff_max, size=(k, k)) for _ in range(q)]\n",
    "    \n",
    "    # Initialize the time series with zeros\n",
    "    Y = np.zeros((n + burn_in, k))  # Extra 100 for burn-in\n",
    "    \n",
    "    # Generate white noise\n",
    "    E = rng.normal(size=(n + burn_in, k))\n",
    "    \n",
    "    # Generate the VMA(q) process\n",
    "    for t in range(q, n + burn_in):\n",
    "        Y[t] = E[t] + sum(B[i] @ E[t - i - 1] for i in range(q))\n",
    "    \n",
    "    if return_noise:\n",
    "        return B, Y[burn_in:], E[burn_in:]  # Discard the burn-in period\n",
    "    return B, Y[burn_in:]  # Discard the burn-in period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707018d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all the coefficients positive and similar amplitude\n",
    "ts_vma_coeff, ts_vma, ts_vma_drive = gen_vma_by_hand(1, 5, 200, coeff_min=0.90, coeff_max=0.99, seed=20251010, return_noise=True)\n",
    "plot_ts(ts_vma, ts_vma_drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3bfa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_vma_coeff, ts_vma, ts_vma_drive = gen_vma_by_hand(2, 3, 200, coeff_max=0.5, seed=20251010, return_noise=True)\n",
    "plot_ts(ts_vma, ts_vma_drive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf21a65b",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- use a single time series\n",
    "- explore the effect of model order p (tip: divide the vma time series by the model order for plotting)\n",
    "- explore the effect of coeff_max on stationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45909d44",
   "metadata": {},
   "source": [
    "## About stationarity tests\n",
    "\n",
    "* ADF: null hypothesis: unit root (non-stationary), can conclude stationarity if $p$-value < alpha\n",
    "* KPSS: null hypothesis: stationary, can conclude non-stationarity if $p$-value < alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8bbbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(adfuller)\n",
    "# help(kpss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c285dfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ADFullerResult(NamedTuple):\n",
    "    adf : float\n",
    "    pvalue : float\n",
    "    usedlag : int\n",
    "    nobs : int\n",
    "    critical_values : dict\n",
    "    icbest : float\n",
    "    resstore : Any = None\n",
    "\n",
    "adf_result = ADFullerResult(*adfuller(ts_var[:, 0], maxlag=5))\n",
    "adf_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc4855",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KPSSResult(NamedTuple):\n",
    "    kpss_stat : float\n",
    "    p_value : float\n",
    "    lags : int\n",
    "    crit : dict\n",
    "    resstore : Any = None\n",
    "\n",
    "kpss_result = KPSSResult(*kpss(ts_var[:, 1], nlags='auto'))\n",
    "kpss_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf855ab",
   "metadata": {},
   "source": [
    "## Autocorrelograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44d29e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_autocorrelograms(x: np.ndarray, lags: int = 40):\n",
    "    \"\"\"Plot ACF and PACF of a time series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array-like, shape (n_samples,)\n",
    "        Time series data.\n",
    "    lags : int\n",
    "        Number of lags to include in the plots.\n",
    "    \"\"\"\n",
    "    acf_vals = acf(x, nlags=lags)\n",
    "    pacf_vals = pacf(x, nlags=lags)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(6, 4))\n",
    "\n",
    "    axes[0].stem(range(lags + 1), acf_vals)\n",
    "    axes[0].set_title('Autocorrelation Function (ACF)')\n",
    "    axes[0].set_xlabel('Lags')\n",
    "    axes[0].set_ylabel('ACF')\n",
    "\n",
    "    axes[1].stem(range(lags + 1), pacf_vals)\n",
    "    axes[1].set_title('Partial Autocorrelation Function (PACF)')\n",
    "    axes[1].set_xlabel('Lags')\n",
    "    axes[1].set_ylabel('PACF')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81091504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AR model\n",
    "coeff_ar, ts_ar = gen_var_by_hand(1, 5, 200, coeff_max=0.5, seed=20251010)\n",
    "coeff_ar = np.array(coeff_ar)[:, 0, 0]\n",
    "ts_ar = ts_ar[:, 0]\n",
    "plot_autocorrelograms(ts_ar, lags=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07590d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MA model\n",
    "coeff_ma, ts_ma = gen_vma_by_hand(1, 5, 200, coeff_max=1.0, seed=20251011)\n",
    "coeff_ma = np.array(coeff_ma)[:, 0, 0]\n",
    "ts_ma = ts_ma[:, 0]\n",
    "plot_autocorrelograms(ts_ma, lags=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4add2f92",
   "metadata": {},
   "source": [
    "## Granger causality test\n",
    "\n",
    "We can follow, for example\n",
    "\n",
    "Ding, M., Chen, Y., & Bressler, S. L. (2006). Granger Causality: Basic Theory and Application to Neuroscience. February. https://doi.org/10.1002/9783527609970.ch17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb44a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix = np.array([[0, 1],\n",
    "                             [0, 0]])\n",
    "\n",
    "coupled_coeff, coupled_ts = gen_var_by_hand(2, 2, 200, coeff_max=0.5, seed=20251010, coupling_mask=adjacency_matrix.T)\n",
    "plot_ts(coupled_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b686b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autocorrelograms of the two observed time series do not reveal the coupling\n",
    "# It would be possible to create cross-correlograms as well\n",
    "plot_autocorrelograms(coupled_ts[:, 0], lags=40)\n",
    "plot_autocorrelograms(coupled_ts[:, 1], lags=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2c4dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(grangercausalitytests)  # 2nd column is tested to cause the 1st column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e11249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y -> X\n",
    "gr_yx = grangercausalitytests(coupled_ts, maxlag=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb5f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X -> Y\n",
    "gr_xy = grangercausalitytests(coupled_ts[:, ::-1], maxlag=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ed46e3",
   "metadata": {},
   "source": [
    "Explain the results\n",
    "\n",
    "- which tests are significant\n",
    "- for what lag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2925d3c",
   "metadata": {},
   "source": [
    "## Explore some real-world data sets as well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6f6ae4",
   "metadata": {},
   "source": [
    "\n",
    "### Epileptic EEG Dataset @ Mendeley Data\n",
    "\n",
    "This dataset includes the EEG of 6 epileptic patients recorded at the Epilepsy monitoring unit of the American university of Beirut Medical Center between January 2014 and July 2015. The data represents measurements from 21 scalp electrodes, following the 10-20 electrode system, sampled at 500 Hz . All channels have been bandpass filtered between 1/1.6 Hz and 70Hz while filtering out the 50Hz (electrical utility frequency).  Some channels have been omitted from specific recordings due to artifact constraints. \n",
    "\n",
    "* By Wassim Nasreddine\n",
    "* Published: 16 March 2021| Version 1 | DOI: 10.17632/5pc2j46cbc.1\n",
    "* Find here: https://data.mendeley.com/datasets/5pc2j46cbc/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61e76bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the epileptic dataset\n",
    "!mkdir data\n",
    "\n",
    "import requests\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "epileptic = {\n",
    "    'x_test': 'https://data.mendeley.com/public-files/datasets/5pc2j46cbc/files/93b81166-0e48-4dc0-ac20-b7167f7606c5/file_downloaded',\n",
    "    'x_train': 'https://data.mendeley.com/public-files/datasets/5pc2j46cbc/files/169dca1c-4992-43d3-9c94-030de59c2524/file_downloaded',\n",
    "    'y_test': 'https://data.mendeley.com/public-files/datasets/5pc2j46cbc/files/adf1c2fd-81ef-4f87-86cc-56d75bba8c31/file_downloaded',\n",
    "    'y_train': 'https://data.mendeley.com/public-files/datasets/5pc2j46cbc/files/62accb90-a1b2-4b50-bde5-fbe6096f165f/file_downloaded'\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": user_agent,\n",
    "    \"Referer\": \"https://data.mendeley.com/\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "}\n",
    "with requests.Session() as sess:\n",
    "    sess.headers.update(headers)\n",
    "    for key, url in epileptic.items():\n",
    "        outpath = f\"data/{key}.npz\"\n",
    "        print(\"Downloading\", key, \"->\", outpath)\n",
    "        try:\n",
    "            r = sess.get(url, stream=True, timeout=30)\n",
    "            if r.status_code == 200:\n",
    "                with open(outpath, \"wb\") as f:\n",
    "                    for chunk in r.iter_content(chunk_size=8192):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "                print(\"Saved\", outpath)\n",
    "            else:\n",
    "                print(\"Failed\", key, r.status_code, r.reason)\n",
    "                print(\" Response headers:\", dict(r.headers))\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(\"Error downloading\", key, e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118f04b5",
   "metadata": {},
   "source": [
    "### Kaggle Epileptic seizures dataset\n",
    "\n",
    "The original dataset from the reference consists of 5 different folders, each with 100 files, with each file representing a single subject/person. Each file is a recording of brain activity for 23.6 seconds. The corresponding time-series is sampled into 4097 data points. Each data point is the value of the EEG recording at a different point in time. So we have total 500 individuals with each has 4097 data points for 23.5 seconds.\n",
    "\n",
    "* https://www.kaggle.com/datasets/chaditya95/epileptic-seizures-dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
