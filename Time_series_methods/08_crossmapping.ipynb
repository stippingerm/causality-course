{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14bef34d",
   "metadata": {},
   "source": [
    "# Inference of causal graphs from data\n",
    "\n",
    "Author: Marcell Stippinger\n",
    "\n",
    "Date: 2025-11-07\n",
    "\n",
    "## Contents\n",
    "\n",
    "* Generate logistic map data\n",
    "* Implement time delay embedding\n",
    "* Do convergent cross-mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf234c26",
   "metadata": {},
   "source": [
    "## Imports and plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be97520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, signal\n",
    "from sklearn.utils import check_random_state\n",
    "from scipy.spatial import cKDTree\n",
    "from typing import NamedTuple, Optional, Tuple, Any\n",
    "# Granger causality test\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7853c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ts(X, E=None, fs=1.0):\n",
    "    \"\"\"Plot time series data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Time series data to plot.\n",
    "    E : array-like, shape (n_samples, n_features), optional\n",
    "        Noise components to overlay on the time series.\n",
    "    fs : float, optional\n",
    "        Sampling frequency of the time series.\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    t = np.arange(n_samples) / fs\n",
    "    fig, axes = plt.subplots(n_features, 1, figsize=(6, 4), sharex=True)\n",
    "    if n_features == 1:\n",
    "        axes = [axes]\n",
    "    for i in range(n_features):\n",
    "        axes[i].axhline(0, color='gray', linestyle='--', linewidth=0.5)\n",
    "        axes[i].plot(t, X[:, i])\n",
    "        if E is not None:\n",
    "            axes[i].plot(t, E[:, i], linestyle='None', marker='o', markersize=3, alpha=0.7, label='Noise')\n",
    "        axes[i].set_title(f'Time Series {i+1}')\n",
    "        axes[i].set_ylabel('Value')\n",
    "    axes[-1].set_xlabel('Time')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf855ab",
   "metadata": {},
   "source": [
    "## Autocorrelograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44d29e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_autocorrelograms(x: np.ndarray, lags: int = 40):\n",
    "    \"\"\"Plot ACF and PACF of a time series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array-like, shape (n_samples,)\n",
    "        Time series data.\n",
    "    lags : int\n",
    "        Number of lags to include in the plots.\n",
    "    \"\"\"\n",
    "    acf_vals = acf(x, nlags=lags)\n",
    "    pacf_vals = pacf(x, nlags=lags)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(6, 4))\n",
    "\n",
    "    axes[0].stem(range(lags + 1), acf_vals)\n",
    "    axes[0].set_title('Autocorrelation Function (ACF)')\n",
    "    axes[0].set_xlabel('Lags')\n",
    "    axes[0].set_ylabel('ACF')\n",
    "\n",
    "    axes[1].stem(range(lags + 1), pacf_vals)\n",
    "    axes[1].set_title('Partial Autocorrelation Function (PACF)')\n",
    "    axes[1].set_xlabel('Lags')\n",
    "    axes[1].set_ylabel('PACF')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4add2f92",
   "metadata": {},
   "source": [
    "## Granger causality test\n",
    "\n",
    "We can follow, for example\n",
    "\n",
    "Ding, M., Chen, Y., & Bressler, S. L. (2006). Granger Causality: Basic Theory and Application to Neuroscience. February. https://doi.org/10.1002/9783527609970.ch17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e11249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y -> X\n",
    "#gr_yx = grangercausalitytests(coupled_ts, maxlag=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb5f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X -> Y\n",
    "#coupled_ts_rev = np.stack((coupled_ts[:, 1], coupled_ts[:, 0]), axis=1)\n",
    "#gr_xy = grangercausalitytests(coupled_ts[:, ::-1], maxlag=4)\n",
    "#gr_xy = grangercausalitytests(coupled_ts_rev, maxlag=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ed46e3",
   "metadata": {},
   "source": [
    "Explain the results\n",
    "\n",
    "- which tests are significant\n",
    "- for what lag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64793d5c",
   "metadata": {},
   "source": [
    "# Coupled logistic maps\n",
    "\n",
    "A single logistic map is generated by\n",
    "$$ x(t+1) = r x(t) (1- x(t)) $$\n",
    "\n",
    "The interaction between logmaps may be additive\n",
    "$$ x(t+1) = r x(t) (1- x(t)) - \\beta y(t) $$\n",
    "or multiplicative\n",
    "$$ x(t+1) = r x(t) (1- x(t) - \\beta y(t)). $$\n",
    "\n",
    "We have to make sure the new value is in $[0, 1]$ therefore we take it modulo $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5bff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _logmap_mul_rhs_modulo(state, r, beta, noise):\n",
    "    \"\"\"\n",
    "    Mapping function of logistic map with circular boundary conditions and\n",
    "    multiplicative coupling\n",
    "\n",
    "    :param state: [X1, X2, ..., Xn], shape (dim, )\n",
    "    :param r: float or array of floats, shape (n, )\n",
    "    :param beta: c_{j-->i} == beta_{ij}, array of floats, shape (n, n)\n",
    "    :param noise: callable, dynamical noise generator\n",
    "    :return: f\n",
    "    \"\"\"\n",
    "    return np.remainder(noise + r * state * (1.0 - state - beta @ state), 1.0)\n",
    "\n",
    "\n",
    "def _logmap_add_rhs_modulo(state, r, beta, noise):\n",
    "    \"\"\"\n",
    "    Mapping function of logistic map with circular boundary conditions and\n",
    "    additive coupling\n",
    "\n",
    "    :param state: [X1, X2, ..., Xn], shape (dim, )\n",
    "    :param r: float or array of floats, shape (n, )\n",
    "    :param beta: c_{j-->i} == beta_{ij}, array of floats, shape (n, n)\n",
    "    :param noise: callable, dynamical noise generator\n",
    "    :return: f\n",
    "    \"\"\"\n",
    "    return np.remainder(noise + r * state * (1.0 - state) - beta @ state, 1.0)\n",
    "\n",
    "def generate_coupled_logmaps(\n",
    "        n_samples: int,\n",
    "        r: Any,\n",
    "        beta: np.ndarray,\n",
    "        noise_std: float = 0.0,\n",
    "        coupling_type: str = 'additive',\n",
    "        random_state: Optional[Any] = None\n",
    "    ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate time series from coupled logistic maps with circular boundary conditions.\n",
    "\n",
    "    :param n_samples: Number of time steps to simulate.\n",
    "    :param r: Growth rate parameter(s) for the logistic maps.\n",
    "    :param beta: Coupling matrix, diagonal empty, shape (n, n).\n",
    "    :param noise_std: Standard deviation of the Gaussian noise.\n",
    "    :param coupling_type: Type of coupling ('additive' or 'multiplicative').\n",
    "    :param random_state: Random state for reproducibility.\n",
    "    :return: Time series data, shape (n_samples, n).\n",
    "    \"\"\"\n",
    "    rng = check_random_state(random_state)\n",
    "    n = beta.shape[0]\n",
    "    state = rng.rand(n)\n",
    "    ts = np.zeros((n_samples, n))\n",
    "\n",
    "    if coupling_type == 'additive':\n",
    "        rhs = _logmap_add_rhs_modulo\n",
    "    elif coupling_type == 'multiplicative':\n",
    "        rhs = _logmap_mul_rhs_modulo\n",
    "    else:\n",
    "        raise ValueError(\"coupling_type must be 'additive' or 'multiplicative'\")\n",
    "\n",
    "    for t in range(n_samples):\n",
    "        noise = rng.normal(0, noise_std, size=n)\n",
    "        ts[t] = state\n",
    "        state = rhs(state, r, beta, noise)\n",
    "\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4adda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x0 -> x1 avagy x -> y\n",
    "\n",
    "coupling = np.array([[0.0, 0.2],\n",
    "                     [0.0, 0.0]])\n",
    "\n",
    "ts = generate_coupled_logmaps(\n",
    "    n_samples=1000,\n",
    "    r=3.8,\n",
    "    beta=coupling.T,\n",
    "    coupling_type='additive',\n",
    "    random_state=20251107,\n",
    "    noise_std=0.1\n",
    ")\n",
    "\n",
    "plot_ts(ts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7d7c35",
   "metadata": {},
   "source": [
    "# Time delay embedding is based on Takens' theorem.\n",
    "\n",
    "We may use numpy's sliding_window_view to create the time delay embedding. (This is good for us, but not efficient for convolution.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc4ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(np.lib.stride_tricks.sliding_window_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fc1ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_delay_embedding(X: np.ndarray, m: int, tau: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Perform time-delay embedding of a time series.\n",
    "\n",
    "    :param X: Time series data, shape (n_samples, n_features).\n",
    "    :param m: Embedding dimension.\n",
    "    :param tau: Time delay.\n",
    "    :return: Embedded time series, shape (n_samples - (m - 1) * tau, n_features * m).\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    n_embedded = n_samples - (m - 1) * tau\n",
    "    embedded = np.zeros((n_embedded, n_features * m))\n",
    "\n",
    "    for i in range(n_embedded):\n",
    "        for j in range(m):\n",
    "            embedded[i, j*n_features:(j+1)*n_features] = X[i + j * tau]\n",
    "\n",
    "    return embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afd4d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_delay_embedding_np(X: np.ndarray, m: int, tau: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Perform time-delay embedding of a time series.\n",
    "\n",
    "    :param X: Time series data, shape (n_samples, n_features).\n",
    "    :param m: Embedding dimension.\n",
    "    :param tau: Time delay.\n",
    "    :return: Embedded time series, shape (n_samples - (m - 1) * tau, n_features * m).\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    n_embedded = n_samples - (m - 1) * tau\n",
    "    embedded = np.zeros((n_embedded, n_features * m))\n",
    "\n",
    "    embedded = np.lib.stride_tricks.sliding_window_view(X, window_shape=(m, n_features))[:, 0, ::tau, :].reshape(n_embedded, n_features * m)\n",
    "\n",
    "    return embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89114c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyparsing import line\n",
    "\n",
    "\n",
    "def show_embedding_3d(X_embedded: np.ndarray, title: str = ''):\n",
    "    \"\"\"\n",
    "    Visualize 3D time-delay embedding.\n",
    "\n",
    "    :param X_embedded: Embedded time series, shape (n_samples, 3).\n",
    "    :param title: Title of the plot.\n",
    "    \"\"\"\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot(X_embedded[:, 0], X_embedded[:, 1], X_embedded[:, 2], marker='o', linestyle='None', markersize=2, alpha=0.7)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('X(t)')\n",
    "    ax.set_ylabel('X(t + τ)')\n",
    "    ax.set_zlabel('X(t + 2τ)')\n",
    "    plt.show()\n",
    "\n",
    "show_embedding_3d(time_delay_embedding(ts[:, 0:1], m=3, tau=1), title='Time-Delay Embedding of X')\n",
    "show_embedding_3d(time_delay_embedding(ts[:, 1:2], m=3, tau=1), title='Time-Delay Embedding of Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c769f0",
   "metadata": {},
   "source": [
    "# Convergent cross-mapping\n",
    "\n",
    "Map neighborhood of manifold $Y$ (consequence) to indices, look for corresponding values in $x$.\n",
    "Compare the average of these values with the actual $x$.\n",
    "\n",
    "* naive neighbor lookup uses all pairwise distances, $O(n^2)$ complexty\n",
    "* in lower dimensions KDTree algorithm is much more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621cac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(cKDTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a9277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_map(source: np.array, target: np.array, k: int):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        source (np.array): n_samples x d_embed\n",
    "        target (np.array): n_samples\n",
    "        k (int): number of neighbors to consider\n",
    "\n",
    "    \"\"\"\n",
    "    tree = cKDTree(source)\n",
    "    # we shall exclude self-matches of points\n",
    "    distances, indices = tree.query(source, k+1)\n",
    "    # search corresponding x values: (n_samples, k)\n",
    "    estimates = target[indices[:, 1:]]\n",
    "    # weights, summing to 1 in every row\n",
    "    weights = np.exp(-distances[:, 1:] / distances[:, 1:2])\n",
    "    weights /= weights.sum(axis=1, keepdims=True)\n",
    "    # estimates\n",
    "    weighted_estimates = (weights * estimates).sum(axis=1)\n",
    "    return weighted_estimates\n",
    "\n",
    "def cross_map_correlation(source: np.array, target: np.array, k: int):\n",
    "    correlations = []\n",
    "    lengths = np.logspace(1, np.log10(len(source)), num=10, dtype=int).astype(int)\n",
    "    for n in lengths:\n",
    "        estimates = cross_map(source[:n], target[:n], k)\n",
    "        corr = np.corrcoef(estimates[:n].flat, target[:n].flat)[0, 1]\n",
    "        correlations.append(corr)\n",
    "    return lengths, correlations\n",
    "\n",
    "def cross_map_correlation_plot(source: np.array, target: np.array, k: int, title: str = ''):\n",
    "    lengths, correlations = cross_map_correlation(source, target, k)\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.plot(lengths, correlations, marker='o')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('Library Size')\n",
    "    ax.set_ylabel('Cross Map Correlation')\n",
    "    ax.set_title(title)\n",
    "    ax.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a2b425",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "* discuss why target is indexed [:, 0], multiple reasons!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee11e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = time_delay_embedding(ts[:, 0:1], m=3, tau=1)\n",
    "y = time_delay_embedding(ts[:, 1:2], m=3, tau=1)\n",
    "\n",
    "print(cross_map_correlation(x, y[:, 0], k=6))\n",
    "print(cross_map_correlation(y, x[:, 0], k=6))\n",
    "\n",
    "cross_map_correlation_plot(x, y[:, 0], k=6, title = 'Y cross-mapped from X (does Y->X?)')\n",
    "cross_map_correlation_plot(y, x[:, 0], k=6, title = 'X cross-mapped from Y (does X->Y?)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3e65d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
